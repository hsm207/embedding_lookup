{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0-dev20201025'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define how long we want the vector embedding to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_SIZE = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a vocabulary that maps a word to an integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>world</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>am</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bye</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>now</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cat</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hat</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>or</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  id\n",
       "0  never   0\n",
       "1      a   1\n",
       "2   good   2\n",
       "3  world   3\n",
       "4     am   4\n",
       "5    bye   5\n",
       "6    now   6\n",
       "7    cat   7\n",
       "8    hat   8\n",
       "9     or   9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {\n",
    "    \"never\": 0,\n",
    "    \"a\": 1,\n",
    "    \"good\": 2,\n",
    "    \"world\": 3,\n",
    "    \"am\": 4,\n",
    "    \"bye\": 5,\n",
    "    \"now\": 6,\n",
    "    \"cat\": 7,\n",
    "    \"hat\": 8,\n",
    "    \"or\": 9\n",
    "}\n",
    "\n",
    "pd.DataFrame({\"word\": vocab.keys(), \"id\": vocab.values()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 10\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(vocab)\n",
    "\n",
    "print(f\"Vocabulary size: {VOCAB_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the `VOCAB_SIZE` X `EMBED_SIZE` embedding table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[7. 3. 2. 6. 8.]\n",
      " [0. 3. 7. 9. 3.]\n",
      " [7. 7. 8. 7. 0.]\n",
      " [0. 8. 8. 6. 9.]\n",
      " [5. 6. 7. 6. 3.]\n",
      " [3. 3. 5. 8. 6.]\n",
      " [9. 3. 4. 4. 1.]\n",
      " [8. 8. 3. 5. 0.]\n",
      " [7. 1. 2. 5. 1.]\n",
      " [4. 5. 4. 3. 9.]], shape=(10, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "embedding_table = np.random.randint(0, 10, size = (VOCAB_SIZE, EMBED_SIZE))\n",
    "embedding_table = tf.convert_to_tensor(embedding_table, tf.float32)\n",
    "print(embedding_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mechanics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define two pieces of text we would like to convert to embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 1: now or never\n",
      "text 2: good bye world\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"now or never\",\n",
    "    \"good bye world\"\n",
    "]\n",
    "\n",
    "for i, text in enumerate(texts, 1):\n",
    "    print(f\"text {i}: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize those texts into words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 1: ['now', 'or', 'never']\n",
      "text 2: ['good', 'bye', 'world']\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = [text.split(' ') for text in texts]\n",
    "\n",
    "for i, tokens in enumerate(tokenized_texts, 1):\n",
    "    print(f\"text {i}: {tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map each word to its id in the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 1: [6, 9, 0]\n",
      "text 2: [2, 5, 3]\n"
     ]
    }
   ],
   "source": [
    "word_ids = [[vocab[word] for word in tokenized_text] \n",
    "            for tokenized_text in tokenized_texts]\n",
    "\n",
    "for i, tokens in enumerate(word_ids, 1):\n",
    "    print(f\"text {i}: {tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a matrix to represent the sequence of word ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[6 9 0]\n",
      " [2 5 3]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "word_ids = tf.convert_to_tensor(word_ids)\n",
    "print(word_ids)THe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each word id can be converted into a one-hot encoded vector of length `VOCAB_SIZE`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]], shape=(2, 3, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "ohe_ids = tf.one_hot(word_ids, VOCAB_SIZE)\n",
    "\n",
    "print(ohe_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the lookup, take each one-hot encoded word id and matrix multiply it with the embedding table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[9. 3. 4. 4. 1.]\n",
      "  [4. 5. 4. 3. 9.]\n",
      "  [7. 3. 2. 6. 8.]]\n",
      "\n",
      " [[7. 7. 8. 7. 0.]\n",
      "  [3. 3. 5. 8. 6.]\n",
      "  [0. 8. 8. 6. 9.]]], shape=(2, 3, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "text_embded_manual = tf.matmul(ohe_ids, embedding_table)\n",
    "print(text_embded_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that by manually doing the lookup ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just verify for text 1\n",
    "expected_output = text_embded_manual[0]\n",
    "\n",
    "text1_ids = word_ids[0]\n",
    "\n",
    "# step 1: do the lookup against the embedding table for each id\n",
    "actual_output = [embedding_table[id] for id in text1_ids]\n",
    "\n",
    "# step 2: add a row dimension\n",
    "actual_output = [tf.expand_dims(emb, 0) for emb in actual_output]\n",
    "\n",
    "# step 3: concatenate at the row dimension\n",
    "actual_output = tf.concat(actual_output, axis=0)\n",
    "\n",
    "# verify\n",
    "assert tf.experimental.numpy.array_equal(expected_output, actual_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shortcuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the content of `word_ids`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[6 9 0]\n",
      " [2 5 3]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(word_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `tf.nn.embedding_lookup`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[9. 3. 4. 4. 1.]\n",
      "  [4. 5. 4. 3. 9.]\n",
      "  [7. 3. 2. 6. 8.]]\n",
      "\n",
      " [[7. 7. 8. 7. 0.]\n",
      "  [3. 3. 5. 8. 6.]\n",
      "  [0. 8. 8. 6. 9.]]], shape=(2, 3, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "text_embed_shortcut1 = tf.nn.embedding_lookup(embedding_table, word_ids)\n",
    "print(text_embed_shortcut1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf.experimental.numpy.array_equal(text_embded_manual, text_embed_shortcut1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, SEQ_LEN = word_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[9. 3. 4. 4. 1.]\n",
      "  [4. 5. 4. 3. 9.]\n",
      "  [7. 3. 2. 6. 8.]]\n",
      "\n",
      " [[7. 7. 8. 7. 0.]\n",
      "  [3. 3. 5. 8. 6.]\n",
      "  [0. 8. 8. 6. 9.]]], shape=(2, 3, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "embeddings_init_fn = tf.keras.initializers.Constant(embedding_table)\n",
    "\n",
    "emb_layer = tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, \n",
    "                                      output_dim=EMBED_SIZE,\n",
    "                                      input_length=SEQ_LEN,\n",
    "                                      embeddings_initializer=embeddings_init_fn,)\n",
    "\n",
    "text_embed_shortcut2 = emb_layer(word_ids)\n",
    "print(text_embed_shortcut2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf.experimental.numpy.array_equal(text_embded_manual, text_embed_shortcut2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
